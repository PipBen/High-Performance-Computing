{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Pip Benjamin Assignment 2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEFiy0b45Ep1"
      },
      "source": [
        "# PART 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3nrs5IDG0DW"
      },
      "source": [
        "The first part of this notebook implements GPU acceleration to evaluate a particle sum. We evaluate the sum $$\n",
        "f(x_i) = \\sum_{j} g(x_i, y_j) c_j\n",
        "$$ for weights $c_j\\in\\mathbb{C}$, targets $x_i\\in\\mathbb{R}^3$ and sources $y_j\\in\\mathbb{R}^3$, where $g(x, y) = e^{-\\frac{|x- y|^2}{2\\sigma^2}}$ is the radial basis function kernel ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mhUhlSziqWju"
      },
      "source": [
        "import numpy as np\n",
        "import numba\n",
        "from numba import cuda\n",
        "import math\n",
        "from scipy.sparse import coo_matrix\n",
        "from scipy.sparse.linalg import spsolve"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rpUn16y3F7bL"
      },
      "source": [
        "We first define a function to generate arrays of $m$ target and $n$ source points and their assosciated weights, as well as defining the number of thread blocks $(\\ell, p)$ in a grid for our GPU implementation, where $\\ell = (m+15) / 16$ and $p = (n + 31) / 32$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29lI4LYC3uYy"
      },
      "source": [
        "def target_source_generate(target_points, nsources):\n",
        "  \"\"\"Generate arrays of target and source points\"\"\"\n",
        "  plot_grid = np.mgrid[0:1:target_points * 1j, 0:1:target_points * 1j]\n",
        "\n",
        "  #define targets, sources and weights in 3 dimensions\n",
        "  targets_xy = np.vstack((plot_grid[0].ravel(),\n",
        "                          plot_grid[1].ravel(),\n",
        "                          np.zeros(plot_grid[0].size, dtype=np.float32))).T\n",
        "\n",
        "  targets_xz = np.vstack((plot_grid[0].ravel(),\n",
        "                          np.zeros(plot_grid[0].size,dtype=np.float32),\n",
        "                          plot_grid[1].ravel())).T\n",
        "\n",
        "  targets_yz = np.vstack((np.zeros(plot_grid[0].size, dtype=np.float32),\n",
        "                        plot_grid[0].ravel(),\n",
        "                        plot_grid[1].ravel())).T\n",
        "\n",
        "  targets = np.float32(np.vstack((targets_xy, targets_xz, targets_yz)))\n",
        "\n",
        "  #total number of targets and sources\n",
        "  m=targets.shape[0]\n",
        "  n=nsources\n",
        "\n",
        "  rand = np.random.RandomState(0)\n",
        "\n",
        "  sources = np.float32(rand.rand(n, 3))\n",
        "\n",
        "  weights = np.float32(rand.rand(n))\n",
        "\n",
        "\n",
        "  #create grid of (l,p) thread blocks\n",
        "  l=(m+15)//SX\n",
        "  p=(n+31)//SY\n",
        "\n",
        "  return targets, sources, weights, n, m, l ,p"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfYPHMjyIk5b"
      },
      "source": [
        "We now define a CUDA kernel to evaluate the rbf function at all target and source points. This takes as inputs the `sources`, `targets` and `weights` defined above, as well as an `intermediate_result` GPU device array of size (m, p). Each value in this array stores the evaluation of each target point over the number of source points in each thread block.\n",
        "\n",
        "A separate CUDA kernel is then defines to sum the partial sums for each target over all thread blocks, producing `final_results`, an array of complete rbf sums for each target point.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biNz73Mo5Mbf"
      },
      "source": [
        "@cuda.jit\n",
        "def rbf_evaluation_cuda_adapted(sources, targets, weights, intermediate_result):\n",
        "  \"\"\"Evaluate the rbf function sum\"\"\"\n",
        "\n",
        "  local_result = cuda.shared.array((SX,SY), numba.float32)\n",
        "  local_targets = cuda.shared.array((SX, 3), numba.float32)\n",
        "  local_sources = cuda.shared.array((SY, 3), numba.float32)\n",
        "  local_weights = cuda.shared.array(SY, numba.float32)\n",
        "\n",
        "  #block position\n",
        "  block_y=cuda.blockIdx.y\n",
        "  block_x=cuda.blockIdx.x\n",
        "\n",
        "  #thread pos within block\n",
        "  tx = cuda.threadIdx.x\n",
        "  ty = cuda.threadIdx.y\n",
        "  \n",
        "  \n",
        "  #global thread position\n",
        "  px, py = cuda.grid(2)\n",
        "\n",
        "  if px >= m:\n",
        "    return\n",
        "  \n",
        "  #import all data within thread block to shared memory to prevent having to read from CPU repeatedly \n",
        "  if ty == 0:\n",
        "    for index in range(3):\n",
        "      local_targets[tx, index] = targets[px, index]\n",
        "\n",
        "    for index in range(SY):\n",
        "            local_result[tx, index] = numba.float32(0)\n",
        "\n",
        "  if tx == 0:\n",
        "    for index in range(3):\n",
        "      local_sources[ty, index] = sources[py, index]\n",
        "    local_weights[ty] = weights[py]\n",
        "\n",
        "\n",
        "  cuda.syncthreads()\n",
        "\n",
        "  #compute local result for all targets and all sources in thread block\n",
        "  squared_diff = numba.float32(0)\n",
        "  for index in range(3):\n",
        "    squared_diff += (local_targets[tx,index] - local_sources[ty,index])**2\n",
        "  local_result[tx,ty] = math.exp(-squared_diff / ( numba.float32(2) * numba.float32(sigma)**2)) * local_weights[ty]\n",
        "\n",
        "  cuda.syncthreads()\n",
        "\n",
        "  #sum values for each target assosciated with each source  and place in intermediate_result array\n",
        "  if ty==0:\n",
        "    res = numba.float32(0)\n",
        "    for index in range(SY):\n",
        "      res += local_result[tx, index]\n",
        "    intermediate_result[px, block_y] =res\n",
        "\n",
        "\n",
        "@cuda.jit\n",
        "def summation_kernel(intermediate_results, final_results):\n",
        "  \"\"\"Sum the total rbf value for each target over all threadblocks\"\"\"\n",
        "  px=cuda.grid(1)\n",
        "  if px >= intermediate_results.shape[0]:\n",
        "    return\n",
        "\n",
        "  threads= cuda.blockDim.x\n",
        "  tx = cuda.threadIdx.x\n",
        "\n",
        "  sum = numba.float32(0)\n",
        "  for index in range(p):\n",
        "    sum+=intermediate_results[px,index]\n",
        "  final_results[px]=sum"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ2mbNBZM00W"
      },
      "source": [
        "We now define a parallelised Python Numba implementation of the rbf sum for comparison."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9CtOFqO3Spu"
      },
      "source": [
        "@numba.njit(parallel=True)\n",
        "def rbf_evaluation(sources, targets, weights, result):\n",
        "    \"\"\"Evaluate the RBF sum.\"\"\"\n",
        "    \n",
        "    n = len(sources)\n",
        "    m = len(targets)\n",
        "        \n",
        "    result[:] = 0\n",
        "    for index in numba.prange(m):\n",
        "        result[index] = np.sum(np.exp(-np.sum(np.abs(targets[index] - sources)**2, axis=1) / (2 * sigma**2)) * weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17wN3C8jMDZ5"
      },
      "source": [
        "We define threadblocks of size (16x32) in a grid of size (l,p) as defined above. The choice of these threadblock dimensions ensures maximum occupancy on each 32 bit register within the GPU's streaming multiprocessors.\n",
        "\n",
        "The arrays `intermediate_result` and `final_results` here are defined as CUDA device arrays before being parsed into their kernels. This prevents unnecessary transfer between the CPU and GPU.\n",
        "\n",
        "Using the Python Numba implementation defined above, and by summing the resulting arrays from both implementations, we can verify that our CUDA implementation is in agreement up to (very nearly) single precission. (There may be a small error in my kernel that I'm missing)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_cuHtCPhKOg6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "887b6d93-dba2-4608-98dd-a4361146fd5e"
      },
      "source": [
        "sigma = .1\n",
        "\n",
        "SX=16\n",
        "SY=32\n",
        "\n",
        "targets, sources,weights, n, m, l ,p = target_source_generate(400,3200)\n",
        "print(targets.shape)\n",
        "intermediate_result_host= np.zeros((m,p), dtype=np.float32)\n",
        "#intermediate_result = cuda.device_array((m,p), dtype=np.float32)\n",
        "intermediate_result=cuda.to_device(intermediate_result_host)\n",
        "rbf_evaluation_cuda_adapted[(l,p), (SX,SY)](sources.astype('float32'), targets.astype('float32'), weights.astype('float32'), intermediate_result)\n",
        "\n",
        "host_intermediate_result= intermediate_result.copy_to_host()\n",
        "\n",
        "final_results = cuda.device_array(m, dtype =np.float32)\n",
        "\n",
        "summation_kernel[(m+31)//32,32](intermediate_result, final_results)\n",
        "host_final_results= final_results.copy_to_host()\n",
        "\n",
        "print(\"CUDA Result: \",np.sum(host_final_results))\n",
        "\n",
        "#python numba implementation\n",
        "result = np.zeros(len(targets), dtype=np.float32)\n",
        "rbf_evaluation(sources, targets, weights, result)\n",
        "print(\"Python Numba Result: \", np.sum(result))\n",
        "  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(480000, 3)\n",
            "CUDA Result:  5241298.0\n",
            "Python Numba Result:  5241297.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SWEdYjFYyx92"
      },
      "source": [
        "## Benchmarking\n",
        "We now examine the effect of varying numbers of source and target points on the runtime of both our CUDA implementation and the Python Numba implementation. Firstly we define methods which include the preparation of sources and the calculation of the rbf sum arrays."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tPfPmem2qvoB"
      },
      "source": [
        "def rbf_process(target_points, nsources):\n",
        "  \"\"\"Produce targets, sources and sum over the rbf function using the CUDA implementation\"\"\"\n",
        "  targets, sources, weights, n, m, l ,p = target_source_generate(target_points,nsources)\n",
        "  intermediate_result = cuda.device_array((m,p), dtype=np.float32)\n",
        "  rbf_evaluation_cuda_adapted[(l,p), (SX,SY)](sources.astype('float32'), targets.astype('float32'), weights.astype('float32'), intermediate_result)\n",
        "  final_results = cuda.device_array(m, dtype =np.float32)\n",
        "  summation_kernel[(m+31)//32,32](intermediate_result, final_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jFjf3z16svb_"
      },
      "source": [
        "def numba_rbf_process(target_points, nsources):\n",
        "  \"\"\"Produce targets, sources and sum over the rbf function using the Python Numba implementation\"\"\"\n",
        "  targets, sources, weights, n, m, l ,p = target_source_generate(target_points,nsources)\n",
        "  result = np.zeros(len(targets), dtype=np.float32)\n",
        "  rbf_evaluation(sources, targets, weights, result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G-f8wFREQb6y"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJNQ1-PpsFAc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "478b2fb0-7570-4700-9a39-1f46bf3f9927"
      },
      "source": [
        "target_points=50; nsources=50\n",
        "m=target_points*target_points*3\n",
        "print(\"n= \", nsources, \", m= \", m)\n",
        "print(\"Cuda implementation:\")\n",
        "%timeit rbf_process(target_points, nsources)\n",
        "print(\"Numba implementation:\")\n",
        "%timeit numba_rbf_process(target_points, nsources)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n=  50 , m=  7500\n",
            "Cuda implementation:\n",
            "100 loops, best of 3: 3.39 ms per loop\n",
            "Numba implementation:\n",
            "100 loops, best of 3: 12.5 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hbMkgAZPvAmh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f97f0c32-53da-4a1e-aea9-eeddbe447cdb"
      },
      "source": [
        "target_points=50; nsources=500\n",
        "m=target_points*target_points*3\n",
        "print(\"n= \", nsources, \", m= \", m)\n",
        "print(\"Cuda implementation:\")\n",
        "%timeit rbf_process(target_points, nsources)\n",
        "print(\"Numba implementation:\")\n",
        "%timeit numba_rbf_process(target_points, nsources)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n=  500 , m=  7500\n",
            "Cuda implementation:\n",
            "100 loops, best of 3: 4.51 ms per loop\n",
            "Numba implementation:\n",
            "10 loops, best of 3: 90.4 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QczcqqVpQHLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "98cd8ea4-db5f-45bf-9cc2-0f93bd51383f"
      },
      "source": [
        "target_points=50; nsources=5000\n",
        "m=target_points*target_points*3\n",
        "print(\"n= \", nsources, \", m= \", m)\n",
        "print(\"Cuda implementation:\")\n",
        "%timeit rbf_process(target_points, nsources)\n",
        "print(\"Numba implementation:\")\n",
        "%timeit numba_rbf_process(target_points, nsources)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n=  5000 , m=  7500\n",
            "Cuda implementation:\n",
            "100 loops, best of 3: 11 ms per loop\n",
            "Numba implementation:\n",
            "1 loop, best of 3: 882 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2k7iuJijveHj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e34a04-e2ab-48f6-8e89-30d776138d0a"
      },
      "source": [
        "target_points=500; nsources=500\n",
        "m=target_points*target_points*3\n",
        "print(\"n= \", nsources, \", m= \", m)\n",
        "print(\"Cuda implementation:\")\n",
        "%timeit rbf_process(target_points, nsources)\n",
        "print(\"Numba implementation:\")\n",
        "%timeit numba_rbf_process(target_points, nsources)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n=  500 , m=  750000\n",
            "Cuda implementation:\n",
            "10 loops, best of 3: 72.8 ms per loop\n",
            "Numba implementation:\n",
            "1 loop, best of 3: 9 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HsNYWPuj4aFa"
      },
      "source": [
        "Here we define the process required to complete the RBF sum computations on the GPU device alone, and find the time taken for various numbers of sources and targets. We see here that a large proportion of the time to run the function is taken up by simply producing the arrays of targets and sources. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgMLTp12y-ly"
      },
      "source": [
        "def rbf_process_on_device(targets, sources, weights, n, m, l ,p):\n",
        "  intermediate_result = cuda.device_array((m,p), dtype=np.float32)\n",
        "  rbf_evaluation_cuda_adapted[(l,p), (SX,SY)](sources.astype('float32'), targets.astype('float32'), weights.astype('float32'), intermediate_result)\n",
        "  final_results = cuda.device_array(m, dtype =np.float32)\n",
        "  summation_kernel[(m+31)//32,32](intermediate_result, final_results)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1AwgKJn8I9L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6af12ae6-e48f-42b3-9ae5-8f458d2d5e83"
      },
      "source": [
        "targets, sources, weights, n, m, l ,p = target_source_generate(50,50)\n",
        "print(\"n= \", n, \", m= \", m)\n",
        "print(\"Cuda implementation:\")\n",
        "%timeit rbf_process_on_device(targets, sources, weights, n, m, l ,p)\n",
        "result = np.zeros(len(targets), dtype=np.float32)\n",
        "print(\"Numba implementation:\")\n",
        "%timeit rbf_evaluation(sources, targets, weights, result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n=  50 , m=  7500\n",
            "Cuda implementation:\n",
            "100 loops, best of 3: 2.8 ms per loop\n",
            "Numba implementation:\n",
            "100 loops, best of 3: 12.1 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1JaQEDel2k5v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73bdcdf0-3ca4-425d-a323-33fd81bbd108"
      },
      "source": [
        "targets, sources, weights, n, m, l ,p = target_source_generate(50,500)\n",
        "print(\"n= \", n, \", m= \", m)\n",
        "print(\"Cuda implementation:\")\n",
        "%timeit rbf_process_on_device(targets, sources, weights, n, m, l ,p)\n",
        "result = np.zeros(len(targets), dtype=np.float32)\n",
        "print(\"Numba implementation:\")\n",
        "%timeit rbf_evaluation(sources, targets, weights, result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n=  500 , m=  7500\n",
            "Cuda implementation:\n",
            "100 loops, best of 3: 3.82 ms per loop\n",
            "Numba implementation:\n",
            "10 loops, best of 3: 90.5 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqvxtAp84zrS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7ebeb082-c451-47e2-e175-65a4acd4ae5b"
      },
      "source": [
        "targets, sources, weights, n, m, l ,p = target_source_generate(5000,1000)\n",
        "print(\"n= \", n, \", m= \", m)\n",
        "print(\"Cuda implementation:\")\n",
        "%timeit rbf_process_on_device(targets, sources, weights, n, m, l ,p)\n",
        "result = np.zeros(len(targets), dtype=np.float32)\n",
        "# print(\"Numba implementation:\")\n",
        "# %timeit rbf_evaluation(sources, targets, weights, result)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "n=  1000 , m=  75000000\n",
            "Cuda implementation:\n",
            "1 loop, best of 3: 3.59 s per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cjgRBSYlz40A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjmPssSFz8SR"
      },
      "source": [
        "### Memory Transfer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlptKt_AR5ee"
      },
      "source": [
        "We now examine the times for memory transfers from CPU to GPU and back for fixed `target_points`=50 and increasing numbers of sources. We observe that these values are significant compared to the times taken for functions defined above. Though copying arrays from the GPU device to the CPU is consistently faster than copying from CPU to GPU, both would cause significant slowdown if arrays in a GPU kernel were repeatedly copied between GPU and CPU."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBIWjf2L0BoT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a2b3f9c7-1f43-4fa8-9685-52fd9a4933ed"
      },
      "source": [
        "targets, sources1, weights, n, m, l ,p = target_source_generate(50,500)\n",
        "print(\"Number of Sources = \", len(sources1))\n",
        "%timeit sources_device1 = cuda.to_device(sources1)\n",
        "targets, sources2, weights, n, m, l ,p = target_source_generate(50,5000)\n",
        "print(\"Number of Sources = \", len(sources2))\n",
        "%timeit sources_device2 = cuda.to_device(sources2)\n",
        "\n",
        "targets, sources3, weights, n, m, l ,p = target_source_generate(50,50000)\n",
        "print(\"Number of Sources = \", len(sources3))\n",
        "%timeit sources_device3 = cuda.to_device(sources3)\n",
        "\n",
        "targets, sources4, weights, n, m, l ,p = target_source_generate(50,500000)\n",
        "print(\"Number of Sources = \", len(sources4))\n",
        "%timeit sources_device4 = cuda.to_device(sources4)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Sources =  500\n",
            "The slowest run took 1836.74 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1 loop, best of 3: 375 µs per loop\n",
            "Number of Sources =  5000\n",
            "1000 loops, best of 3: 398 µs per loop\n",
            "Number of Sources =  50000\n",
            "1000 loops, best of 3: 753 µs per loop\n",
            "Number of Sources =  500000\n",
            "1000 loops, best of 3: 1.7 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RV8hQWSJ2TuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81aa1070-dae9-40db-946f-f3a6f7c6ecb6"
      },
      "source": [
        "sources_device1 = cuda.to_device(sources1)\n",
        "sources_device2 = cuda.to_device(sources2)\n",
        "sources_device3 = cuda.to_device(sources3)\n",
        "sources_device4 = cuda.to_device(sources4)\n",
        "\n",
        "print(\"Number of Sources = \", len(sources1))\n",
        "%timeit sources_device1.copy_to_host()\n",
        "print(\"Number of Sources = \", len(sources2))\n",
        "%timeit sources_device2.copy_to_host()\n",
        "print(\"Number of Sources = \", len(sources3))\n",
        "%timeit sources_device3.copy_to_host()\n",
        "print(\"Number of Sources = \", len(sources4))\n",
        "%timeit sources_device4.copy_to_host()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of Sources =  500\n",
            "The slowest run took 11.19 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 3: 65.1 µs per loop\n",
            "Number of Sources =  5000\n",
            "The slowest run took 9.88 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "10000 loops, best of 3: 79.2 µs per loop\n",
            "Number of Sources =  50000\n",
            "1000 loops, best of 3: 282 µs per loop\n",
            "Number of Sources =  500000\n",
            "1000 loops, best of 3: 1.23 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kWbqjvy6s0sc"
      },
      "source": [
        "# PART 2\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5rDcSj5TPoB"
      },
      "source": [
        "We now move on to analyse the Poisson problem$$\n",
        "-\\Delta u = 1\n",
        "$$ on the unit square $\\Omega = [0, 1]^2$ with $x = 0$ on $\\partial\\Omega$. This problem can be set up as a discrete linear matrix problem $ A x = f $ if we discretise points $(x_i, y_j)$ in the unit square such that $x_i = ih$, $y_j = jh$ where $h = \\frac{1}{N - 1}$ such that each point $u(x_i, y_j)$ has value $u_{i,j}$. $u_{i,j}$ can then be represented as a 1D vector $u_{i, j} = x_{jN + i}$.\n",
        "\n",
        "The LHS of the linear matrix problem can be approximated as $$\n",
        "-\\Delta u_{i, j}\\approx \\frac{4u_{i, j} - u_{i - 1, j} - u_{i + 1, j} - u_{i, j - 1} - u_{i, j+ 1}}{h^2}.\n",
        "$$\n",
        "\n",
        "Below we define a GPU accelerated kernel to compute the LHS matrix-vector product without the explicit creation of the matrix $A$. This kernel is then compared to a non GPU accelerated method which explicitly creates a sparse matrix representing $A$ in order to solve the linear matrix problem."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cVJiqNAatyEt"
      },
      "source": [
        "@cuda.jit\n",
        "def poisson_kernel(x,device_f):\n",
        "\n",
        "  \"\"\"if thread is boundary value- write corresponding u_i,j value in reslut array\n",
        "  if thread is assoc with interior point- evaluate 5 point stencil for corresponding interior point\"\"\"\n",
        "\n",
        "  thread=cuda.blockIdx.x\n",
        "\n",
        "  if thread > x.shape[0]:\n",
        "    return\n",
        "\n",
        "  #the associated row and column in 2d array u_i,j for each value in the 1d array 'x'\n",
        "  i = thread // N\n",
        "  j = thread - (i * N)\n",
        "  \n",
        "  #boundary condition\n",
        "  if i == 0  or i==N-1 or j==0 or j==N-1:\n",
        "    device_f[thread] = x[thread]\n",
        "  #five-point stencil\n",
        "  else:\n",
        "    device_f[thread] = ( 4*x[thread] - x[thread-1] - x[thread+1] - x[thread-N] - x[thread+N])/(h*h)\n",
        "  cuda.syncthreads()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fzSYtrKls2yP"
      },
      "source": [
        "\n",
        "\n",
        "def discretise_poisson(N):\n",
        "    \"\"\"Generate the matrix and rhs associated with the discrete Poisson operator.\"\"\"\n",
        "    \n",
        "    nelements = 5 * N**2 - 16 * N + 16\n",
        "    \n",
        "    row_ind = np.empty(nelements, dtype=np.float64)\n",
        "    col_ind = np.empty(nelements, dtype=np.float64)\n",
        "    data = np.empty(nelements, dtype=np.float64)\n",
        "    \n",
        "    f = np.empty(N * N, dtype=np.float64)\n",
        "    \n",
        "    count = 0\n",
        "    for j in range(N):\n",
        "        for i in range(N):\n",
        "            if i == 0 or i == N - 1 or j == 0 or j == N - 1:\n",
        "                row_ind[count] = col_ind[count] = j * N + i\n",
        "                data[count] =  1\n",
        "                f[j * N + i] = 0\n",
        "                count += 1\n",
        "                \n",
        "            else:\n",
        "                row_ind[count : count + 5] = j * N + i\n",
        "                col_ind[count] = j * N + i\n",
        "                col_ind[count + 1] = j * N + i + 1\n",
        "                col_ind[count + 2] = j * N + i - 1\n",
        "                col_ind[count + 3] = (j + 1) * N + i\n",
        "                col_ind[count + 4] = (j - 1) * N + i\n",
        "                                \n",
        "                data[count] = 4 * (N - 1)**2\n",
        "                data[count + 1 : count + 5] = - (N - 1)**2\n",
        "                f[j * N + i] = 1\n",
        "                \n",
        "                count += 5                                 \n",
        "    return coo_matrix((data, (row_ind, col_ind)), shape=(N**2, N**2)).tocsr(), f"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhv5P3EvWsUC"
      },
      "source": [
        "We now define a Numba parrallelised function to compute the matrix-vector product of a CSR matrix and a vector."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jvy-P-3Vjv_T"
      },
      "source": [
        "@numba.jit(nopython=True, parallel=True)\n",
        "def csr_matvec(data, indices, indptr, shape, x):\n",
        "    \"\"\"Evaluates the matrix-vector product with a CSR matrix.\"\"\"\n",
        "    # Get the rows and columns\n",
        "    \n",
        "    m, n = shape\n",
        "    \n",
        "    y = np.zeros(m, dtype=np.float64)\n",
        "        \n",
        "    for row_index in numba.prange(m):\n",
        "        col_start = indptr[row_index]\n",
        "        col_end = indptr[row_index + 1]\n",
        "        for col_index in range(col_start, col_end):\n",
        "            y[row_index] += data[col_index] * x[indices[col_index]]\n",
        "            \n",
        "    return y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KmLSxSuWfTd"
      },
      "source": [
        "Having defined our two methods for computing the result of the matrix-vector multiplication, we can set up a distribution of $u_{i,j}$ values and transform into a 1D vector `x`. We can then explicitly compute the matrix-vector product $Ax$ using the non-GPU accelerated function and compare to our CUDA function.\n",
        "\n",
        "We find here that the error between the result matrices produced by the two functions is zero, validating our CUDA accelerated method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jv5N3vqOPSDN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f27b105c-ac96-4e13-e1b0-909c50a3c6c7"
      },
      "source": [
        "N=100\n",
        "h=1/(N-1)\n",
        "Nsq=N*N\n",
        "\n",
        "#set up initial distribution u, convert to 1darray x\n",
        "u=np.zeros((N,N))\n",
        "\n",
        "for n in range (1,int(N/2 +1/2)+1):\n",
        "    u[n:(N-1)-(n-1), n:(N-1)-(n-1)]=n*n\n",
        "\n",
        "x=np.zeros(N*N, dtype=np.float32)\n",
        "for i in range(N):\n",
        "  for j in range(N):\n",
        "    x[j * N + i] =u[i,j]\n",
        "\n",
        "\n",
        "#sparse matrix\n",
        "A, f = discretise_poisson(N)\n",
        "sparse_f =  csr_matvec(A.data, A.indices, A.indptr, A.shape, x)\n",
        "\n",
        "#cuda implementation\n",
        "device_x = cuda.to_device(x)\n",
        "device_f = cuda.device_array((N*N,), dtype=np.float32)\n",
        "poisson_kernel[Nsq,1](device_x,device_f)\n",
        "host_f = device_f.copy_to_host()\n",
        "\n",
        "\n",
        "rel_error = np.linalg.norm(sparse_f - host_f, np.inf) / np.linalg.norm(host_f, np.inf)\n",
        "print(f\"Error: {round(rel_error, 2)}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIBiqYrTNRPj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a6fb0a0-fa50-4110-f128-75c0a611d419"
      },
      "source": [
        "sol = spsolve(A, f)\n",
        "y = csr_matvec(A.data, A.indices, A.indptr, A.shape, sol)\n",
        "\n",
        "device_sol = cuda.to_device(sol)\n",
        "device_y = cuda.device_array((N*N,), dtype=np.float32)\n",
        "poisson_kernel[Nsq,1](device_sol,device_y)\n",
        "host_y = device_y.copy_to_host()\n",
        "\n",
        "rel_error = np.linalg.norm(y - host_y, np.inf) / np.linalg.norm(host_y, np.inf)\n",
        "print(f\"Error: {round(rel_error, 2)}.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Error: 0.0.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49SgLV8W-Cr7"
      },
      "source": [
        "## Benchmarking"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y8OPTqIhYOvN"
      },
      "source": [
        "Here we set up a loop over values of matrix dimension $N$, to find the time taken for our CUDA accelerated function to compute the result array. Time could be saved here by splitting the values in `x` into threadblocks of a greater number of threads and loading these values into the shared memory for each block, rather than accessing the global memory to find each data point in the five-point stencil as is currently the case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O2G6TFHA-EjG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "209426fe-5687-4b1b-c246-d1eaf1155ece"
      },
      "source": [
        "N_array= np.linspace(10,3000,10).astype(np.int32)\n",
        "\n",
        "for N in N_array:\n",
        "  h=1/(N-1)\n",
        "  Nsq=N*N\n",
        "\n",
        "  #set up initial distribution u, convert to 1darray x\n",
        "  u=np.zeros((N,N))\n",
        "\n",
        "  for n in range (1,int(N/2 +1/2)+1):\n",
        "      u[n:(N-1)-(n-1), n:(N-1)-(n-1)]=n*n\n",
        "\n",
        "  x=np.zeros(N*N, dtype=np.float32)\n",
        "  for i in range(N):\n",
        "    for j in range(N):\n",
        "      x[j * N + i] =u[i,j]\n",
        "\n",
        "  device_f = cuda.device_array((N*N,), dtype=np.float32)\n",
        "  print(\"N=\",N,\":\")\n",
        "  %timeit -n 50 poisson_kernel[Nsq,1](x,device_f)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "N= 10 :\n",
            "50 loops, best of 3: 826 µs per loop\n",
            "N= 342 :\n",
            "50 loops, best of 3: 2.46 ms per loop\n",
            "N= 674 :\n",
            "50 loops, best of 3: 5.85 ms per loop\n",
            "N= 1006 :\n",
            "50 loops, best of 3: 11.6 ms per loop\n",
            "N= 1338 :\n",
            "50 loops, best of 3: 19.7 ms per loop\n",
            "N= 1671 :\n",
            "50 loops, best of 3: 30.4 ms per loop\n",
            "N= 2003 :\n",
            "50 loops, best of 3: 43.1 ms per loop\n",
            "N= 2335 :\n",
            "50 loops, best of 3: 58.2 ms per loop\n",
            "N= 2667 :\n",
            "50 loops, best of 3: 75.4 ms per loop\n",
            "N= 3000 :\n",
            "50 loops, best of 3: 95.2 ms per loop\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fzk-3KQD-YIH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}